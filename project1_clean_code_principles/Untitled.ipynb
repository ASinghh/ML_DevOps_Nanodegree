{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76128f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A library of functions to find customers who are likely to churn\n",
    "\n",
    "Author: Ashutosh Singh\n",
    "\n",
    "Date: 12th of February, 2023\n",
    "'''\n",
    "\n",
    "# Import Packages\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import plot_roc_curve, classification_report\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['QT_QPA_PLATFORM']='offscreen'\n",
    "\n",
    "def import_data(pth):\n",
    "    '''\n",
    "    returns dataframe for the csv found at pth\n",
    "\n",
    "    input:\n",
    "            pth: a path to the csv\n",
    "    output:\n",
    "            df: pandas dataframe\n",
    "    '''\n",
    "    return pd.read_csv(pth)\n",
    "\n",
    "def create_dir_struct(dir_list = [\"images\", \"images/eda\", \"images/results\", \"logs\", \"models\", \"dataset_characteristics\"]):\n",
    "    '''\n",
    "    This function checks for required directory structure and creates the\n",
    "    directories that are missing.\n",
    "    \n",
    "    Adding dataset_characteristics to save outputs from the df.head(),\n",
    "    df.shape, and  df.isnull.sum(), and df.describe().\n",
    "    \n",
    "    input:\n",
    "            dir_list: list of directory names\n",
    "    output:\n",
    "            None\n",
    "    '''\n",
    "    for dirct in dir_list:\n",
    "        path = r\"./\" + dirct\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "def perform_eda(df):\n",
    "    '''\n",
    "    perform eda on df and save figures to images folder\n",
    "    input:\n",
    "            df: pandas dataframe\n",
    "\n",
    "    output:\n",
    "            None\n",
    "    '''\n",
    "    # Create the required directory strucutre\n",
    "    create_dir_struct()\n",
    "    \n",
    "    # Save dataset characteristics to files for manual viewing\n",
    "    df.head().to_csv(r'./dataset_characteristics/df_head')\n",
    "    np.savetxt(r'./dataset_characteristics/df_shape', df.shape, fmt='%d')\n",
    "    df.isnull().sum().to_csv(r'./dataset_characteristics/df_null_counts')\n",
    "    df.describe().to_csv(r'./dataset_characteristics/df_description')\n",
    "    \n",
    "    # Create binary variable for Churn\n",
    "    if 'Churn' not in df:\n",
    "        df['Churn'] = df['Attrition_Flag'].apply(lambda val: 0 if val==\"Existing Customer\" else 1)\n",
    "    \n",
    "    # Create and save the binary churn distribution\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    df['Attrition_Flag'].hist()\n",
    "    plt.savefig(fname='./images/eda/churn_distribution.jpeg')\n",
    "    \n",
    "    # Create and save customer age distribution\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    df['Customer_Age'].hist()\n",
    "    plt.savefig(fname='./images/eda/customer_age_distribution.png')\n",
    "\n",
    "    # Create and save marital status distribution\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    df.Marital_Status.value_counts('normalize').plot(kind='bar')\n",
    "    plt.savefig(fname='./images/eda/marital_status_distribution.png')\n",
    "\n",
    "    # Create and save total transaction distribution\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.histplot(df['Total_Trans_Ct'], stat='density', kde=True)\n",
    "    plt.savefig(fname='./images/eda/total_transaction_distribution.png')\n",
    "\n",
    "    #  Create and save correlation heat map\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.heatmap(df.corr(), annot=False, cmap='Dark2_r', linewidths = 2)\n",
    "    plt.savefig(fname='./images/eda/heatmap.png')\n",
    "\n",
    "\n",
    "def encoder_helper(df, category_lst , response):\n",
    "    '''\n",
    "    helper function to turn each categorical column into a new column with\n",
    "    propotion of churn for each category - associated with cell 15 from the notebook\n",
    "\n",
    "    input:\n",
    "            df: pandas dataframe\n",
    "            category_lst: list of columns that contain categorical features\n",
    "            response: string of response name [optional argument that could be used for naming variables or index y column]\n",
    "\n",
    "    output:\n",
    "            df: pandas dataframe with new columns for analysis\n",
    "    '''\n",
    "\n",
    "    for category in category_lst:\n",
    "        column_lst = []\n",
    "        column_groups = df.groupby(category).mean()['Churn']\n",
    "\n",
    "        for val in df[category]:\n",
    "            column_lst.append(column_groups.loc[val])\n",
    "\n",
    "        if response:\n",
    "            df[category + '_' + response] = column_lst\n",
    "        else:\n",
    "            df[category] = column_lst\n",
    "    return df\n",
    "\n",
    "def perform_feature_engineering(df, response = 'Churn'):\n",
    "    '''\n",
    "    input:\n",
    "              df: pandas dataframe\n",
    "              response: string of response name [optional argument that could be used for naming variables or index y column]\n",
    "\n",
    "    output:\n",
    "              X_train: X training data\n",
    "              X_test: X testing data\n",
    "              y_train: y training data\n",
    "              y_test: y testing data\n",
    "    '''\n",
    "    # Creating binary variable 'Chrun', for cases when EDA is not performed\n",
    "    if 'Churn' not in df:\n",
    "        df['Churn'] = df['Attrition_Flag'].apply(lambda val: 0 if val==\"Existing Customer\" else 1)\n",
    "    \n",
    "    # categorical features\n",
    "    cat_columns = ['Gender', 'Education_Level', 'Marital_Status','Income_Category', 'Card_Category' ]\n",
    "\n",
    "    # feature engineering\n",
    "    df = encoder_helper(df, cat_columns, response)\n",
    "\n",
    "    # target feature \n",
    "    y = df['Churn']     \n",
    "\n",
    "    # Create dataframe\n",
    "    X = pd.DataFrame()         \n",
    "\n",
    "    keep_cols = ['Customer_Age', 'Dependent_count', 'Months_on_book',\n",
    "                 'Total_Relationship_Count', 'Months_Inactive_12_mon',\n",
    "                 'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n",
    "                 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',\n",
    "                 'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio',\n",
    "                 'Gender_Churn', 'Education_Level_Churn', 'Marital_Status_Churn',\n",
    "                 'Income_Category_Churn', 'Card_Category_Churn']\n",
    "\n",
    "    # Features DataFrame\n",
    "    X[keep_cols] = df[keep_cols]\n",
    "\n",
    "    # Train and Test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)  \n",
    "\n",
    "    return (X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "def classification_report_image(y_train,\n",
    "                                y_test,\n",
    "                                y_train_preds,\n",
    "                                y_test_preds, model_name, result_dir):\n",
    "    '''\n",
    "    produces classification report for training and testing results and stores report as image\n",
    "    in images folder. Changing parameters to make more modular.\n",
    "    input:\n",
    "            y_train      : Pandas Dataframe- training response values\n",
    "            y_test       : Pandas Dataframe- test response values\n",
    "            y_train_preds: Pandas Dataframe- training predictions from the fitted model\n",
    "            y_test_preds : Pandas Dataframe- test predictions from the fitted model\n",
    "            model_name   : str- Name of the classifier\n",
    "            result_dir   : str- Path of dir to store report image\n",
    "\n",
    "    output:\n",
    "             None\n",
    "    '''\n",
    "    plt.rc('figure', figsize=(5, 5))\n",
    "    plt.text(0.01, 1.25, str(model_name + ' Test'), {'fontsize': 10}, fontproperties = 'monospace')\n",
    "    plt.text(0.01, 0.05, str(classification_report(y_test, y_test_preds)), {'fontsize': 10}, fontproperties = 'monospace')\n",
    "    plt.text(0.01, 0.6, str(model_name +' Train'), {'fontsize': 10}, fontproperties = 'monospace')\n",
    "    plt.text(0.01, 0.7, str(classification_report(y_train, y_train_preds)), {'fontsize': 10}, fontproperties = 'monospace')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    result_file = result_dir + model_name + '_classf_rep' + '.png'\n",
    "    plt.savefig(fname= result_file)\n",
    "    \n",
    "    \n",
    "def feature_importance_plot(model_file, X_data, output_pth):\n",
    "    '''\n",
    "    creates and stores the feature importances in pth\n",
    "    input:\n",
    "            model     : model object containing feature_importances_\n",
    "            X_data    : pandas dataframe of X values\n",
    "            output_pth: path to store the figure\n",
    "\n",
    "    output:\n",
    "             None\n",
    "    '''\n",
    "    \n",
    "    ## Putting a test to check if the clf has feature importance feature\n",
    "    try:\n",
    "        # Loading model\n",
    "        model_obj = joblib.load(model_file)\n",
    "        model_name = (model_file.split(\"/\")[-1]).split(\".\")[0]\n",
    "        \n",
    "        # Feature importances\n",
    "        importances = model_obj.feature_importances_\n",
    "\n",
    "        # Sort Feature importances in descending order\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "\n",
    "        # Sorted feature importances\n",
    "        names = [X_data.columns[i] for i in indices]\n",
    "\n",
    "        # Create plot\n",
    "        plt.figure(figsize=(25, 15))\n",
    "\n",
    "        # Create plot title\n",
    "        plt.title(model_name + \" Feature Importance\")\n",
    "        plt.ylabel('Importance')\n",
    "\n",
    "        # Add bars\n",
    "        plt.bar(range(X_data.shape[1]), importances[indices])\n",
    "\n",
    "        # x-axis labels\n",
    "        plt.xticks(range(X_data.shape[1]), names, rotation=90)\n",
    "\n",
    "        # Save the image\n",
    "        plt.savefig(fname=output_pth + model_name + '_feature_importances.png')\n",
    "    \n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "def roc_plotter(model, X_test, y_test, roc_file):\n",
    "    '''\n",
    "    Function to draw the ROC graph and saving it to a file.\n",
    "    input:\n",
    "            model   : model object containing feature_importances_\n",
    "            X_test  : pandas dataframe of test feature set\n",
    "            y_test  : pandas dataframe of test target variables\n",
    "            roc_file: file to save the plot at\n",
    "\n",
    "    output:\n",
    "             None\n",
    "    '''\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    display = plot_roc_curve(model,X_test, y_test)                              \n",
    "    plt.savefig(fname= roc_file)\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "def train_models(df, model_dir, result_dir, clf, param_grid = None):\n",
    "    '''\n",
    "    train, store model results: images + scores, and store models. Adding more function parameters\n",
    "    to make this function more modular\n",
    "    input:\n",
    "              X_train    : Pandas Dataframe- X training data\n",
    "              X_test     : Pandas Dataframe- X testing data\n",
    "              y_train    : Pandas Dataframe- y training data\n",
    "              y_test     : Pandas Dataframe- y testing data\n",
    "              model_dir  : str- Path of dir to save final model\n",
    "              result_dir : str- Path of dir to save results\n",
    "              clf        : SkLearn Classifier\n",
    "              param_grid : {str(hyper_param:[value]}- Parameter grid for grid search\n",
    "    output:\n",
    "              None\n",
    "    '''\n",
    "    # Creating directory structure for cases when EDA is not performed\n",
    "    create_dir_struct()\n",
    "    \n",
    "    # Seperating Features and target variable, and performing train-test split\n",
    "    X_train, X_test, y_train, y_test = perform_feature_engineering(df, response = 'Churn')\n",
    "    \n",
    "    # Checking for parameter grid, preforming grid search if the grid is provided\n",
    "    # and fitting the classifier\n",
    "    if param_grid != None:\n",
    "        model = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5)\n",
    "        model.fit(X_train, y_train)\n",
    "        model = model.best_estimator_\n",
    "        \n",
    "    else:\n",
    "        model = clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Performing inference on feature sets\n",
    "    y_train_preds = model.predict(X_train)\n",
    "    y_test_preds  = model.predict(X_test)\n",
    "    \n",
    "    # Generating model file name \n",
    "    model_name = str(clf)\n",
    "    model_file = model_dir + model_name + '.pkl'\n",
    "    roc_file = result_dir + 'roc_curve_' + model_name + '.png'\n",
    "    \n",
    "    # Saving the best model\n",
    "    joblib.dump(model, model_file)\n",
    "    \n",
    "    # Plotting and saving the ROC Curve\n",
    "    roc_plotter(model, X_test, y_test, roc_file)\n",
    "    \n",
    "    # Creating and saving the classification_report\n",
    "    classification_report_image(y_train,\n",
    "                                y_test,\n",
    "                                y_train_preds,\n",
    "                                y_test_preds, model_name, result_dir)\n",
    "    \n",
    "    # Creating and saving the Feature Importance plot(for classifiers that support this option)\n",
    "    feature_importance_plot(model_file, X_test, result_dir)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Import data\n",
    "    BANK_DF = import_data(pth='./data/bank_data.csv')\n",
    "\n",
    "    # Perform EDA \n",
    "    EDA_DF = perform_eda(df=BANK_DF)\n",
    "    \n",
    "    # Initializing (classifier, parameter grid) tuple for sample runs\n",
    "    clf_paramGrid = [(RandomForestClassifier(random_state=42),{'n_estimators': [200, 500],\n",
    "                  'max_features': ['auto', 'sqrt'],\n",
    "                  'max_depth' : [4, 5, 100],\n",
    "                  'criterion' :['gini', 'entropy']}),(LogisticRegression(solver='lbfgs', max_iter=3000),None)]\n",
    "    \n",
    "    # Initializing directories to save models and results\n",
    "    model_dir = r'./models/'\n",
    "    result_dir = r'./images/results/'\n",
    "    \n",
    "    # Sample runs\n",
    "    for clf, param_grid in clf_paramGrid:\n",
    "        train_models(df = BANK_DF,model_dir = model_dir , result_dir = result_dir,clf=clf,param_grid = param_grid)\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40a300c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
